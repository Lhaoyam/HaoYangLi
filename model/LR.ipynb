{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "import os\n",
    "os.chdir('E:\\work\\mine')   #   改变当前工作目录到指定路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_new=pd.read_csv(r\"extract\\All_feature\\features\\Group5.csv\",header=None)\n",
    "y_new= pd.read_csv(r'extract\\label.csv',header=None)\n",
    "\n",
    "# X_new= X_new[:,1:]\n",
    "print(X_new.shape)\n",
    "print(y_new.shape)\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 使用 StandardScaler 进行标准化\n",
    "scaler = StandardScaler()\n",
    "X_new = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 寻找最佳参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics       # 提供数学统计的函数和工具，如平均数、中位数、众数\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# dataset splitting   将数据集分割成几个较小的独立的部分，包括训练集、验证集、测试集，保证模型在不同的数据子集上都有良好的表现\n",
    "from sklearn.model_selection import train_test_split\n",
    "#   20%的数据作为测试集，80%作为训练集\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=1111)\n",
    "\n",
    "print(X_train_whole.shape)\n",
    "print(X_ind_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# 定义参数范围\n",
    "param_grid = {'C': np.logspace(-3, 3, num=100), 'max_iter': [5000]}\n",
    "\n",
    "# 初始化逻辑回归模型\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# 初始化网格搜索\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=10, scoring='balanced_accuracy')\n",
    "\n",
    "# 在训练数据上进行网格搜索\n",
    "grid_search.fit(X_train_whole, y_train_whole)\n",
    "\n",
    "# 输出最优参数组合\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# 输出最优参数组合下的平均值和标准差\n",
    "print(\"Best mean balanced accuracy:\", round(grid_search.best_score_, 3))\n",
    "print(\"Standard deviation of balanced accuracy:\", round(grid_search.cv_results_['std_test_score'][grid_search.best_index_], 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 k-fold cross vaild\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=1111)\n",
    "\n",
    "BACC_collecton = []\n",
    "ACC_collection = []\n",
    "Sn_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "AUC_collection = []\n",
    "AP=[]\n",
    "\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "y_pred_proba_all = []\n",
    "\n",
    "mean_recall = np.linspace(0, 1, 100)        \n",
    "all_precision = []      \n",
    "\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0         \n",
    "\n",
    "interp_tpr_collection = []      \n",
    "\n",
    "def categorical_probas_to_classes(p):      \n",
    "    return np.argmax(p, axis=1)       \n",
    "# model\n",
    "clf = LogisticRegression(C=0.014174741629268055 , max_iter=5000)  \n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "    \n",
    "    X_train, X_valid, y_train, y_valid = np.take(X_train_whole, train.tolist(), axis=0), np.take(X_train_whole,\n",
    "                                                                                                    test.tolist(),\n",
    "                                                                                                    axis=0), np.take(\n",
    "        y_train_whole, train.tolist(), axis=0), np.take(y_train_whole, test.tolist(), axis=0)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_proba = clf.predict_proba(X_valid)\n",
    "\n",
    "    y_valid_pred = categorical_probas_to_classes(y_pred_proba)\n",
    "\n",
    "\n",
    "    y_true_all.extend(y_valid.ravel().astype(int))\n",
    "    y_pred_all.extend(y_valid_pred.astype(int))\n",
    "    y_pred_proba_all.extend(y_pred_proba[:,1])\n",
    "\n",
    "    TP, FP, FN, TN = confusion_matrix(y_valid, y_valid_pred).ravel()\n",
    "    Sn_collection.append(TP/(TP+FN))\n",
    "    Sp_collection.append(TN/(TN+FP))\n",
    "    ACC_collection.append((TP+TN)/(TP+TN+FP+FN))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collection.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "\n",
    "    auc = roc_auc_score(y_valid, y_pred_proba[:, 1])\n",
    "    AUC_collection.append(auc)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted_Proba': np.round(y_pred_proba_all, 8),\n",
    "    'True_Label': y_true_all,\n",
    "    'Predicted_Label': y_pred_all\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "# results_df.to_csv(r'Result/LR/10折/LR_ESM.csv', index=False)  \n",
    "\n",
    "# 输出结果\n",
    "print(round(statistics.mean(ACC_collection),3),'±',round(statistics.stdev(ACC_collection),3))    \n",
    "print(round(statistics.mean(Sn_collection),3),'±',round(statistics.stdev(Sn_collection),3))\n",
    "print(round(statistics.mean(Sp_collection),3),'±',round(statistics.stdev(Sp_collection),3))\n",
    "print(round(statistics.mean(MCC_collection),3),'±',round(statistics.stdev(MCC_collection),3))\n",
    "print(round(statistics.mean(AUC_collection),3),'±',round(statistics.stdev(AUC_collection),3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 独立测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independence test\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# result collection list\n",
    "BACC_collecton = []\n",
    "ACC_collection = []\n",
    "Sn_collecton = []\n",
    "Sp_collecton = []\n",
    "MCC_collecton = []\n",
    "AUC_collecton = []\n",
    "AP=[]\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "all_precision = []\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0\n",
    "# 新的TPR集合\n",
    "interp_tpr_collection = []\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=i)\n",
    "    clf = LogisticRegression(C = 17.47528400007683, max_iter=5000)\n",
    "    clf.fit(X_train_whole, y_train_whole)   \n",
    "    y_pred_score = clf.predict_proba(X_ind_test)\n",
    "    y_pred = categorical_probas_to_classes(y_pred_score)    \n",
    "    y_true = y_ind_test                 \n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel() \n",
    "    Sn_collecton.append(TP/(TP+FN))\n",
    "    Sp_collecton.append(TN/(TN+FP))\n",
    "    ACC_collection.append((TP+TN)/(TP+TN+FP+FN))\n",
    "    MCC = (TP*TN-FP*FN)/math.pow(((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)),0.5)\n",
    "    MCC_collecton.append(MCC)\n",
    "    BACC_collecton.append(0.5*TP/(TP+FN)+0.5*TN/(TN+FP))\n",
    "    auc = roc_auc_score(y_true, y_pred_score[:, 1])\n",
    "    AUC_collecton.append(auc)\n",
    "  \n",
    "    \n",
    "print(round(statistics.mean(ACC_collection),3),'±',round(statistics.stdev(ACC_collection),3))\n",
    "print(round(statistics.mean(Sn_collecton),3),'±',round(statistics.stdev(Sn_collecton),3))\n",
    "print(round(statistics.mean(Sp_collecton),3),'±',round(statistics.stdev(Sp_collecton),3))\n",
    "print(round(statistics.mean(MCC_collecton),3),'±',round(statistics.stdev(MCC_collecton),3))\n",
    "print(round(statistics.mean(AUC_collecton),3),'±',round(statistics.stdev(AUC_collecton),3))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
