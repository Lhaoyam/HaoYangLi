{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "import os\n",
    "os.chdir('E:\\work\\mine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_new=pd.read_csv(r\"extract\\All_feature\\features\\TPC.csv\", header=None)\n",
    "y_new= pd.read_csv(r'extract\\label.csv', header=None)\n",
    "\n",
    "X_new = X_new.iloc[:,:]\n",
    "print(X_new.shape)\n",
    "print(y_new.shape)\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 使用 StandardScaler 进行标准化\n",
    "scaler = StandardScaler()\n",
    "X_new = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=1111)\n",
    "\n",
    "print(X_train_whole.shape)\n",
    "print(X_ind_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# 定义PLS模型的参数范围\n",
    "parameters = {\n",
    "    'n_components': range(1, 20, 1),  # 成分数量\n",
    "    'scale': [True, False],  # 是否进行标准化\n",
    "    'max_iter': [100, 200, 300],  # 最大迭代次数\n",
    "    'tol': [0.0001, 0.001, 0.01]  # 收敛阈值\n",
    "}\n",
    "\n",
    "# 初始化PLS模型\n",
    "pls = PLSRegression()\n",
    "\n",
    "# 初始化十折网格搜索\n",
    "grid_search = GridSearchCV(estimator=pls, param_grid=parameters, cv=10, scoring='neg_mean_squared_error')\n",
    "\n",
    "# 在训练数据上进行网格搜索\n",
    "grid_search.fit(X_train_whole, y_train_whole)\n",
    "\n",
    "# 获取网格搜索结果\n",
    "best_params = grid_search.best_params_\n",
    "best_mean_score = -grid_search.best_score_  # 注意要取负号，因为scoring设置为neg_mean_squared_error\n",
    "best_std_score = np.std(grid_search.cv_results_['std_test_score'][grid_search.best_index_])\n",
    "\n",
    "# 打印结果\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(\"Best mean squared error:\", best_mean_score)\n",
    "print(\"Standard deviation of best mean squared error:\", best_std_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, train_test_split \n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, average_precision_score, precision_recall_curve\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "import math \n",
    "import numpy as np\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Split dataset into training and independent test sets\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=1111)\n",
    "\n",
    "# Result collection lists\n",
    "BACC_collection = []\n",
    "AAC_collection = []\n",
    "Sn_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "AUC_collection = []\n",
    "AP = []\n",
    "\n",
    "# Initialize lists to store predictions and true values for each fold\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "y_pred_proba_all = []\n",
    "\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "all_precision = []\n",
    "base_fpr = np.linspace(0, 1, 100)\n",
    "mean_tpr = 0.0\n",
    "interp_tpr_collection = []\n",
    "\n",
    "pls = PLSRegression(max_iter=100, n_components=1, scale=False, tol=0.0001)\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "    X_train, X_valid, y_train, y_valid = X_train_whole[train], X_train_whole[test], y_train_whole[train], y_train_whole[test]\n",
    "    pls.fit(X_train, y_train)\n",
    "\n",
    " \n",
    "    y_pred = pls.predict(X_valid).ravel()\n",
    "    y_pred_proba = y_pred  \n",
    "    y_pred_proba = np.clip(y_pred_proba, 0, 1)\n",
    "    y_valid_pred = np.where(y_pred_proba > 0.5, 1, 0)\n",
    "\n",
    "    # Save predictions and true values for this fold\n",
    "    y_true_all.extend(y_valid.ravel().astype(int))\n",
    "    y_pred_all.extend(y_valid_pred.astype(int))\n",
    "    y_pred_proba_all.extend(y_pred_proba)\n",
    "\n",
    "    TP, FP, FN, TN = confusion_matrix(y_valid, y_valid_pred).ravel()\n",
    "    Sn_collection.append(TP / (TP + FN))\n",
    "    AAC_collection.append((TP + TN) / (TP + TN + FP + FN))\n",
    "    Sp_collection.append(TN / (TN + FP))\n",
    "    MCC = (TP * TN - FP * FN) / math.pow(((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)), 0.5)\n",
    "    MCC_collection.append(MCC)\n",
    "    BACC_collection.append(0.5 * TP / (TP + FN) + 0.5 * TN / (TN + FP))\n",
    "    auc = roc_auc_score(y_valid, y_pred)\n",
    "    AUC_collection.append(auc)\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_valid, y_pred)\n",
    "    interp_tpr = np.interp(base_fpr, fpr, tpr)\n",
    "    interp_tpr[0] = 0.0\n",
    "    interp_tpr_collection.append(interp_tpr)\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_valid, y_pred)\n",
    "    average_precision = average_precision_score(y_valid, y_pred)\n",
    "    recall = np.flipud(recall)\n",
    "    precision = np.flipud(precision)\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted_Proba': np.round(y_pred_proba_all, 8),  \n",
    "    'True_Label': y_true_all,\n",
    "    'Predicted_Label': y_pred_all\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "# results_df.to_csv('Result\\PLS\\\\10折/PLS_AAC.csv', index=False)\n",
    "\n",
    "# Print results\n",
    "print(round(statistics.mean(AAC_collection), 3), '±', round(statistics.stdev(AAC_collection), 3))\n",
    "print(round(statistics.mean(Sn_collection), 3), '±', round(statistics.stdev(Sn_collection), 3))\n",
    "print(round(statistics.mean(Sp_collection), 3), '±', round(statistics.stdev(Sp_collection), 3))\n",
    "print(round(statistics.mean(MCC_collection), 3), '±', round(statistics.stdev(MCC_collection), 3))\n",
    "print(round(statistics.mean(AUC_collection), 3), '±', round(statistics.stdev(AUC_collection), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 独立测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import pandas as pd\n",
    "\n",
    "# result collection list\n",
    "BACC_collection = []\n",
    "AAC_collection = []\n",
    "Sn_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "AUC_collection = []\n",
    "\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "y_pred_proba_all = []\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "for i in range(10):\n",
    "  \n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=i)\n",
    "    pls = PLSRegression(max_iter=100, n_components=15, scale=False, tol=0.0001)  # PLS model\n",
    "    pls.fit(X_train_whole, y_train_whole)   # fitting model\n",
    "    \n",
    "    # get predicted values\n",
    "    y_pred_score = pls.predict(X_ind_test)\n",
    "    y_pred_proba = np.clip(y_pred_score, 0, 1)\n",
    "    y_pred = np.where(y_pred_score > 0.5, 1, 0)    \n",
    "    y_true = y_ind_test                \n",
    "    \n",
    "    # Save predictions and true values for this fold\n",
    "    y_true_all.extend(y_true.ravel().astype(int))\n",
    "    y_pred_all.extend(y_pred.astype(int))\n",
    "    y_pred_proba_all.extend(y_pred_proba.ravel())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    TP, FP, FN, TN = confusion_matrix(y_true, y_pred).ravel()\n",
    "    Sn_collection.append(TP / (TP + FN))\n",
    "    AAC_collection.append((TP + TN) / (TP + TN + FP + FN))\n",
    "    Sp_collection.append(TN / (TN + FP))\n",
    "    MCC = (TP * TN - FP * FN) / math.pow(((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)), 0.5)\n",
    "    MCC_collection.append(MCC)\n",
    "    BACC_collection.append(0.5 * TP / (TP + FN) + 0.5 * TN / (TN + FP))\n",
    "    auc = roc_auc_score(y_true, y_pred_score)\n",
    "    AUC_collection.append(auc)\n",
    "\n",
    "# Combine all predictions and true values into a DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Predicted_Proba': np.round(y_pred_proba_all, 8), \n",
    "    'True_Label': y_true_all,\n",
    "    'Predicted_Label': np.array(y_pred_all).flatten()\n",
    "})\n",
    "\n",
    "# Save the results to a CSV file\n",
    "# results_df.to_csv('Result\\PLS\\独立测试/PLS_G5.csv', index=False)\n",
    "\n",
    "# Print mean and standard deviation of collected metrics\n",
    "print(round(statistics.mean(AAC_collection), 3), '±', round(statistics.stdev(AAC_collection), 3))\n",
    "print(round(statistics.mean(Sn_collection), 3), '±', round(statistics.stdev(Sn_collection), 3))\n",
    "print(round(statistics.mean(Sp_collection), 3), '±', round(statistics.stdev(Sp_collection), 3))\n",
    "print(round(statistics.mean(MCC_collection), 3), '±', round(statistics.stdev(MCC_collection), 3))\n",
    "print(round(statistics.mean(AUC_collection), 3), '±', round(statistics.stdev(AUC_collection), 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
