{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current directory\n",
    "import os\n",
    "os.chdir('E:\\work\\mine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "X_new=pd.read_csv(r\"extract\\All_feature\\mRMR\\TPC_Group1\\mRMR_TAPA_500.csv\", header=None)\n",
    "y_new= pd.read_csv(r'extract\\label.csv', header=None)\n",
    "\n",
    "# y_new = y_new.values.ravel()\n",
    "print(X_new.shape)\n",
    "print(y_new.shape)\n",
    "X_new = np.array(X_new)\n",
    "y_new = np.array(y_new).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 使用 StandardScaler 进行标准化\n",
    "scaler = StandardScaler()\n",
    "X_new = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=1111)\n",
    "\n",
    "print(X_train_whole.shape)\n",
    "print(X_ind_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10折交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=1111)\n",
    "BACC_collection = []\n",
    "ACC_collection = []\n",
    "Sn_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "AUC_collection = []\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "\n",
    "svm_model = SVC(C = 1,degree=1, kernel='rbf',  probability=True, random_state=1111)\n",
    "lr_model = LogisticRegression(C = 0.014174741629268055 ,max_iter=5000)\n",
    "pls_model = PLSRegression(max_iter= 100, n_components=3, scale=True, tol=0.0001)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "for train, test in skf.split(X_train_whole, y_train_whole):\n",
    "    X_train, X_valid, y_train, y_valid = X_train_whole[train], X_train_whole[test], y_train_whole[train], y_train_whole[test]\n",
    "\n",
    "    # 训练模型\n",
    "    svm_model.fit(X_train, y_train)\n",
    "    lr_model.fit(X_train, y_train)\n",
    "    pls_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    # 预测\n",
    "    svm_proba = svm_model.predict_proba(X_valid) \n",
    "    svm_proba = svm_proba[:, 1]\n",
    "\n",
    "    lr_proba = lr_model.predict_proba(X_valid) \n",
    "    lr_proba = lr_proba[:, 1]\n",
    "\n",
    "    pls_proba = pls_model.predict(X_valid) \n",
    "    pls_proba = np.clip(pls_proba, 0, 1)\n",
    "    pls_proba = np.reshape(pls_proba, -1)   # 将二维数组展平为一维\n",
    "\n",
    "    # 平均投票\n",
    "    y_pred_proba = (lr_proba  + svm_proba +pls_proba + et_proba + nb_proba + knn_proba)/6\n",
    "    y_valid_pred = np.where(y_pred_proba < 0.5, 0, 1)\n",
    "\n",
    "    TP, FP, FN, TN = confusion_matrix(y_valid, y_valid_pred).ravel()\n",
    "    Sn_collection.append(TP / (TP + FN))\n",
    "    Sp_collection.append(TN / (TN + FP))\n",
    "    MCC = (TP*TN-FP*FN)/np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    MCC_collection.append(MCC)\n",
    "    ACC_collection.append((TP + TN) / (TP + TN + FP + FN))\n",
    "    BACC_collection.append(0.5 * (TP / (TP + FN)) + 0.5 * (TN / (TN + FP)))\n",
    "    auc = roc_auc_score(y_valid, y_pred_proba)\n",
    "    AUC_collection.append(auc)\n",
    "\n",
    "# 输出结果\n",
    "print(round(np.mean(ACC_collection),3), '±', round(np.std(ACC_collection),3))\n",
    "print(round(np.mean(Sn_collection),3), '±', round(np.std(Sn_collection),3))\n",
    "print(round(np.mean(Sp_collection),3), '±', round(np.std(Sp_collection),3))\n",
    "print(round(np.mean(MCC_collection),3), '±', round(np.std(MCC_collection),3))\n",
    "print(round(np.mean(AUC_collection),3), '±', round(np.std(AUC_collection),3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
    "import numpy as np\n",
    "import statistics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "X_train_whole, X_ind_test, y_train_whole, y_ind_test =  train_test_split( X_new, y_new, test_size=0.2, random_state=1111)\n",
    "BACC_collection = []\n",
    "ACC_collection = []\n",
    "Sn_collection = []\n",
    "Sp_collection = []\n",
    "MCC_collection = []\n",
    "AUC_collection = []\n",
    "\n",
    "def categorical_probas_to_classes(p):\n",
    "    return np.argmax(p, axis=1)\n",
    "for i in range(10):\n",
    "    # dataset splitting\n",
    "    X_train_whole, X_ind_test, y_train_whole, y_ind_test = train_test_split(X_new, y_new, test_size=0.2, random_state=i)\n",
    "    svm_model = SVC(C = 1,degree=1, kernel='rbf',  probability=True, random_state=1111)\n",
    "    lr_model = LogisticRegression(C =  0.014174741629268055 ,max_iter=5000)\n",
    "    pls_model = PLSRegression(max_iter= 100, n_components=3, scale=True, tol=0.0001)\n",
    "    \n",
    "    # 训练模型\n",
    "    svm_model.fit(X_train_whole,y_train_whole)\n",
    "    lr_model.fit(X_train_whole, y_train_whole)\n",
    "    pls_model.fit(X_train_whole, y_train_whole)\n",
    "\n",
    "    # 预测\n",
    "    svm_proba = svm_model.predict_proba(X_ind_test) \n",
    "    svm_proba = svm_proba[:, 1]\n",
    "\n",
    "    lr_proba = lr_model.predict_proba(X_ind_test) \n",
    "    lr_proba = lr_proba[:, 1]\n",
    "\n",
    "    pls_proba = pls_model.predict(X_ind_test) \n",
    "    pls_proba = np.clip(pls_proba, 0, 1)\n",
    "    pls_proba = np.reshape(pls_proba, -1)   # 将二维数组展平为一维\n",
    "\n",
    "    # 平均投票\n",
    "    y_pred_proba = (lr_proba  + svm_proba + pls_proba + et_proba + nb_proba +knn_proba)/6\n",
    "    y_valid_pred = np.where(y_pred_proba < 0.5, 0, 1)\n",
    "\n",
    "    TP, FP, FN, TN = confusion_matrix(y_ind_test, y_valid_pred).ravel()\n",
    "    Sn_collection.append(TP / (TP + FN))\n",
    "    Sp_collection.append(TN / (TN + FP))\n",
    "    MCC = (TP*TN-FP*FN)/np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    MCC_collection.append(MCC)\n",
    "    ACC_collection.append((TP + TN) / (TP + TN + FP + FN))\n",
    "    BACC_collection.append(0.5 * (TP / (TP + FN)) + 0.5 * (TN / (TN + FP)))\n",
    "    auc = roc_auc_score(y_ind_test, y_pred_proba)\n",
    "    AUC_collection.append(auc)\n",
    "\n",
    "print(round(statistics.mean(ACC_collection),3),'±',round(statistics.stdev(ACC_collection),3))\n",
    "print(round(statistics.mean(Sn_collection),3),'±',round(statistics.stdev(Sn_collection),3))\n",
    "print(round(statistics.mean(Sp_collection),3),'±',round(statistics.stdev(Sp_collection),3))\n",
    "print(round(statistics.mean(MCC_collection),3),'±',round(statistics.stdev(MCC_collection),3))\n",
    "print(round(statistics.mean(AUC_collection),3),'±',round(statistics.stdev(AUC_collection),3))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
